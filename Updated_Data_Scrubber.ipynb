{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports needed for the methods in this py file.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main tag where I load in the data I scrapped, clean it and then save it to a .csv file\n",
    "def main(file, stringclean):\n",
    "    loadeddata = loadindata(file)\n",
    "    cleaned_data = mrclean(loadeddata, stringclean)\n",
    "    # Convert it to a Dataframe object and save it to a .csv\n",
    "    DF_CD = pd.DataFrame(cleaned_data)\n",
    "    alleduatt = pd.read_csv('AllEduAttainment.csv')\n",
    "    DF_CD.columns = ['Index', 'City Name', 'Population', 'Average Income', 'Percent of Men in City', 'Percent of Women in City', 'Per Capita Income', 'Median House Value', 'Racial Breakdown', 'County']\n",
    "    alleduatt.columns = ['Index', 'County', 'Higher Degree', 'H.S Diploma', 'No H.S Diploma']\n",
    "\n",
    "    # Do secondary cleaning to remove all additional special characters\n",
    "    DF_CD = cd_file_cleanpass2(DF_CD)\n",
    "    alleduatt = all_edu_cleaner(alleduatt)\n",
    "\n",
    "    # Save files to CSV files\n",
    "    DF_CD.to_csv('Fully_Cleaned_CD_Data', sep='\\t', encoding='utf-8')\n",
    "    alleduatt.to_csv('Fully_Cleaned_AEA_Data', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to read in data I saved off with CD_scraping.py for cleaning\n",
    "def loadindata(file):\n",
    "    arr = list()\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            arr.append(line)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def loadincsv(filename):\n",
    "    pssa = pd.read_csv(filename)\n",
    "    print(pssa)\n",
    "    return pssa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second pass on cleaning data in preparation for data analysis, this uses some of the more advanced methods we learned in class\n",
    "def cd_file_cleanpass2(data):\n",
    "    # Remove $ and , from Average Income\n",
    "    data['Average Income'] = data['Average Income'].str.replace('$', '')\n",
    "    data['Average Income'] = data['Average Income'].str.replace(',', '')\n",
    "\n",
    "    # Remove $ and , from Per Capita Income\n",
    "    data['Per Capita Income'] = data['Per Capita Income'].str.replace('$', '')\n",
    "    data['Per Capita Income'] = data['Per Capita Income'].str.replace(',', '')\n",
    "\n",
    "    # Remove $ and , from Median House Value\n",
    "    data['Median House Value'] = data['Median House Value'].str.replace('$', '')\n",
    "    data['Median House Value'] = data['Median House Value'].str.replace(',', '')\n",
    "\n",
    "    # Remove % from Men and Women percentages in city\n",
    "    data['Percent of Men in City'] = data['Percent of Men in City'].str.replace('%', '')\n",
    "    data['Percent of Women in City'] = data['Percent of Women in City'].str.replace('%', '')\n",
    "\n",
    "    # The racial data might take some more time to clean up\n",
    "\n",
    "    # Get my county column in the same format as other files so we can user DataFram.Merge call\n",
    "    data['County'] = data['County'].str.replace(' ', '-').str.strip()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_edu_cleaner(data):\n",
    "    # Clean out all % signs from the educational attainment dataset\n",
    "    data['Higher Degree'] = data['Higher Degree'].str.replace('%', '')\n",
    "    data['H.S Diploma'] = data['H.S Diploma'].str.replace('%', '')\n",
    "    data['No H.S Diploma'] = data['No H.S Diploma'].str.replace('%', '')\n",
    "    data['County'] = data['County'].str.strip()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to take in all rows of city data and clean each element\n",
    "def mrclean(array):\n",
    "    cdata = list()\n",
    "    for i in range(len(array)):\n",
    "        dataarray = array[i].split(\"',\")\n",
    "\n",
    "        # Grab and clean city name\n",
    "        cityarray = dataarray[0][2:]\n",
    "\n",
    "        metricarray = dataarray[1].split(\"|\")\n",
    "\n",
    "        # Grab and clean city population\n",
    "        poparray = metricarray[0].split(\" \")[2]\n",
    "\n",
    "        # Grab and clean average age\n",
    "        agearray = metricarray[1].split(\" \")[1][4:]\n",
    "\n",
    "        # Grab and clean average income\n",
    "        avgincarray = metricarray[2].lstrip().split(\" \")[0]\n",
    "\n",
    "        # Grab and clean percent of men in counties\n",
    "        permenarray = metricarray[3][6:-2]\n",
    "\n",
    "        # Grab and clean percent of women in counties\n",
    "        perwomarray = metricarray[4][6:-2]\n",
    "\n",
    "        # Grab and clean per capita income\n",
    "        percaparray = metricarray[5].lstrip().split(\" \")[0]\n",
    "\n",
    "        # Grab Median House value and clean it\n",
    "        if metricarray[6].strip()[-1] == 'n':\n",
    "            mhvarray = metricarray[6].strip()[:-4]\n",
    "        elif metricarray[6].strip()[-1] == '(':\n",
    "            mhvarray = metricarray[6].strip()[:-2]\n",
    "\n",
    "        # Grab Racial Breakdown and clean it\n",
    "        racearray = metricarray[7]\n",
    "        try:\n",
    "            if racearray[-4:-1] == \"])]\":\n",
    "                racearray\n",
    "            elif racearray.strip() == \"[]\":\n",
    "                racearray = \"*\"\n",
    "            else:\n",
    "                racearray = racearray + \" \" + dataarray[-1].split(\" | \")[0][5:]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Grab county and clean it\n",
    "        try:\n",
    "            countyarray = dataarray[-1].split(\" | \")[-1][0:-3]\n",
    "        except:\n",
    "            countyarray = \"***\"\n",
    "\n",
    "        ip = [cityarray, poparray, agearray, avgincarray, permenarray, perwomarray, percaparray, mhvarray, racearray, countyarray]\n",
    "        cdata.append(ip)\n",
    "    return cdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'all_cities.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a1c9774b17e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"all_cities.py\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mcsvfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadincsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2016_PSSA_School_Level_Perfomance_Results.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-d515b9e77fe5>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Main tag where I load in the data I scrapped, clean it and then save it to a .csv file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mloadeddata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadindata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mcleaned_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmrclean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloadeddata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Convert it to a Dataframe object and save it to a .csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-d70694b4b2e0>\u001b[0m in \u001b[0;36mloadindata\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloadindata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'all_cities.py'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(\"all_cities.py\")\n",
    "    # csvfile = loadincsv('2016_PSSA_School_Level_Perfomance_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
